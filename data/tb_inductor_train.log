cuda train BERT_pytorch                        1.390x p=0.00
TIMING: entire_frame_compile:17.06336 backend_compile:14.50502
STATS: call_* op count: 538 | FakeTensorMode.__torch_dispatch__:43886 | FakeTensor.__torch_dispatch__:6521 | ProxyTorchDispatchMode.__torch_dispatch__:19951
Dynamo produced 1 graphs covering 538 ops with 5 graph breaks (4 unique)
cuda train Background_Matting                  1.054x p=0.00
TIMING: entire_frame_compile:17.72566 backend_compile:13.87574
STATS: call_* op count: 183 | FakeTensorMode.__torch_dispatch__:28585 | FakeTensor.__torch_dispatch__:6090 | ProxyTorchDispatchMode.__torch_dispatch__:10925
Dynamo produced 1 graphs covering 183 ops with 5 graph breaks (4 unique)
cuda train LearningToPaint                     1.132x p=0.00
TIMING: entire_frame_compile:8.66671 backend_compile:7.76268
STATS: call_* op count: 71 | FakeTensor.__torch_dispatch__:2216 | FakeTensorMode.__torch_dispatch__:10710 | ProxyTorchDispatchMode.__torch_dispatch__:4051
Dynamo produced 1 graphs covering 71 ops with 5 graph breaks (4 unique)
WARNING:root:Super_SloMo failed to load
Eager model failed to run
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1146, in validate_model
    self.model_iter_fn(model, example_inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in forward_and_backward_pass
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/Super_SloMo/model_wrapper.py", line 34, in forward
    fCoeff = model.getFlowCoeff(trainFrameIndex, I0.device)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/Super_SloMo/slomo_model.py", line 324, in getFlowCoeff
    C11 = C00 = - (1 - (t[ind])) * (t[ind])
RuntimeError: indices should be either on cpu or on the same device as the indexed tensor (cpu)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 2269, in run
    ) = runner.load_model(device, model_name, batch_size=batch_size)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 311, in load_model
    self.validate_model(model, example_inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1148, in validate_model
    raise NotImplementedError("Eager model failed to run") from e
NotImplementedError: Eager model failed to run

cuda train alexnet                             1.085x p=0.00
TIMING: entire_frame_compile:4.27503 backend_compile:3.90845
STATS: call_* op count: 22 | FakeTensor.__torch_dispatch__:567 | FakeTensorMode.__torch_dispatch__:1798 | ProxyTorchDispatchMode.__torch_dispatch__:691
Dynamo produced 1 graphs covering 22 ops with 5 graph breaks (4 unique)
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 386, in <module>
    torchbench_main()
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 382, in torchbench_main
    main(TorchBenchmarkRunner(), original_dir)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1919, in main
    return maybe_fresh_cache(
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 988, in inner
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 2269, in run
    ) = runner.load_model(device, model_name, batch_size=batch_size)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 249, in load_model
    module = importlib.import_module(f"torchbenchmark.models.{model_name}")
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/attention_is_all_you_need_pytorch/__init__.py", line 12, in <module>
    from torchbenchmark.util.torchtext_legacy.field import Field
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/util/torchtext_legacy/field.py", line 6, in <module>
    from .data import Dataset
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/util/torchtext_legacy/data.py", line 13, in <module>
    from torchtext.data.utils import RandomShuffler
  File "/scratch/voz/work/torchtext/torchtext/__init__.py", line 6, in <module>
    from torchtext import _extension  # noqa: F401
  File "/scratch/voz/work/torchtext/torchtext/_extension.py", line 64, in <module>
    _init_extension()
  File "/scratch/voz/work/torchtext/torchtext/_extension.py", line 58, in _init_extension
    _load_lib("libtorchtext")
  File "/scratch/voz/work/torchtext/torchtext/_extension.py", line 50, in _load_lib
    torch.ops.load_library(path)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_ops.py", line 643, in load_library
    ctypes.CDLL(path)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: /scratch/voz/work/torchtext/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
ERROR
cuda train dcgan                               1.168x p=0.00
TIMING: entire_frame_compile:4.58599 backend_compile:4.22726
STATS: call_* op count: 13 | FakeTensor.__torch_dispatch__:396 | FakeTensorMode.__torch_dispatch__:1740 | ProxyTorchDispatchMode.__torch_dispatch__:667
Dynamo produced 1 graphs covering 13 ops with 5 graph breaks (4 unique)
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 386, in <module>
    torchbench_main()
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 382, in torchbench_main
    main(TorchBenchmarkRunner(), original_dir)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1919, in main
    return maybe_fresh_cache(
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 988, in inner
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 2269, in run
    ) = runner.load_model(device, model_name, batch_size=batch_size)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 275, in load_model
    benchmark = benchmark_cls(
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/util/model.py", line 13, in __call__
    obj = type.__call__(cls, *args, **kwargs)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/demucs/__init__.py", line 50, in __init__
    model.to(device)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1145, in to
    return self._apply(convert)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 202, in _apply
    self._init_flat_weights()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 139, in _init_flat_weights
    self.flatten_parameters()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 169, in flatten_parameters
    not torch.backends.cudnn.is_acceptable(fw.data)):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/backends/cudnn/__init__.py", line 97, in is_acceptable
    if not _init():
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/backends/cudnn/__init__.py", line 52, in _init
    raise RuntimeError(f'{base_error_msg}'
RuntimeError: cuDNN version incompatibility: PyTorch was compiled  against (8, 5, 0) but found runtime version (8, 4, 1). PyTorch already comes bundled with cuDNN. One option to resolving this error is to ensure PyTorch can find the bundled cuDNN.Looks like your LD_LIBRARY_PATH contains incompatible version of cudnnPlease either remove it from the path or install cudnn (8, 5, 0)
ERROR
cuda train densenet121                         ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 670, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.fake_example_inputs())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 1055, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/inductor.py", line 9, in inductor
    return compile_fx(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 455, in compile_fx
    return aot_autograd(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 48, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2805, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2498, in create_aot_dispatcher_function
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1713, in aot_wrapper_dedupe
    return compiler_fn(flat_fn, leaf_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2133, in aot_dispatch_autograd
    compiled_fw_func = aot_config.fw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 430, in fw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/hm/chmz74dpseomabaerourh6l7cmou5qnn67d7dduuflldb6sgc4yy.py", line 9782, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in <graph break in forward_and_backward_pass>
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 337, in catch_errors
    return callback(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 404, in _convert_frame
    result = inner_convert(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 104, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 262, in _convert_frame_assert
    return _compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 324, in _compile
    out_code = transform_code_object(code, transform)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 445, in transform_code_object
    transformations(instructions, code_options)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 311, in transform
    tracer.run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1726, in run
    super().run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 576, in run
    and self.step()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 540, in step
    getattr(self, inst.opname)(inst)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1792, in RETURN_VALUE
    self.output.compile_subgraph(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 517, in compile_subgraph
    self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 588, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 675, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: inductor raised FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True

ERROR
cuda train dlrm                                1.110x p=0.00
TIMING: entire_frame_compile:12.78083 backend_compile:12.42058
STATS: call_* op count: 36 | FakeTensor.__torch_dispatch__:303 | FakeTensorMode.__torch_dispatch__:2614 | ProxyTorchDispatchMode.__torch_dispatch__:1139
Dynamo produced 1 graphs covering 36 ops with 4 graph breaks (3 unique)
cuda train drq                                 ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 670, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.fake_example_inputs())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 1055, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/inductor.py", line 9, in inductor
    return compile_fx(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 455, in compile_fx
    return aot_autograd(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 48, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2805, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2498, in create_aot_dispatcher_function
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1713, in aot_wrapper_dedupe
    return compiler_fn(flat_fn, leaf_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2133, in aot_dispatch_autograd
    compiled_fw_func = aot_config.fw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 430, in fw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/4m/c4mv46pp5fxjhlxdgdd74id4leaerpbrot7li3jmoxrwugq3m45s.py", line 265, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in <graph break in forward_and_backward_pass>
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 337, in catch_errors
    return callback(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 404, in _convert_frame
    result = inner_convert(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 104, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 262, in _convert_frame_assert
    return _compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 324, in _compile
    out_code = transform_code_object(code, transform)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 445, in transform_code_object
    transformations(instructions, code_options)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 311, in transform
    tracer.run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1726, in run
    super().run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 576, in run
    and self.step()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 540, in step
    getattr(self, inst.opname)(inst)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1792, in RETURN_VALUE
    self.output.compile_subgraph(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 541, in compile_subgraph
    self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 588, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 675, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: inductor raised FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True

ERROR
cuda train fastNLP_Bert                        ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 670, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.fake_example_inputs())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 1055, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/inductor.py", line 9, in inductor
    return compile_fx(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 455, in compile_fx
    return aot_autograd(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 48, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2805, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2498, in create_aot_dispatcher_function
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1713, in aot_wrapper_dedupe
    return compiler_fn(flat_fn, leaf_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1326, in aot_dispatch_base
    compiled_fw = aot_config.fw_compiler(fw_module, flat_args_with_views_handled)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 430, in fw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/nr/cnrnkljojkkrhyogfxt4cgisp7znralngefsxekn3zzgvkd4lk2s.py", line 112, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in <graph break in forward_and_backward_pass>
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/fastNLP/models/bert.py", line 265, in forward
    sequence_output = self.bert(words)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/fastNLP/embeddings/bert_embedding.py", line 137, in forward
    outputs = self.model(words)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 337, in catch_errors
    return callback(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 404, in _convert_frame
    result = inner_convert(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 104, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 262, in _convert_frame_assert
    return _compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 324, in _compile
    out_code = transform_code_object(code, transform)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 445, in transform_code_object
    transformations(instructions, code_options)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 311, in transform
    tracer.run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1726, in run
    super().run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 576, in run
    and self.step()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 540, in step
    getattr(self, inst.opname)(inst)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 372, in wrapper
    self.output.compile_subgraph(self, reason=reason)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 541, in compile_subgraph
    self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 588, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 675, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: inductor raised FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True

ERROR
cuda train hf_Albert                           1.581x p=0.00
TIMING: entire_frame_compile:12.21049 backend_compile:10.58092
STATS: call_* op count: 436 | FakeTensorMode.__torch_dispatch__:32425 | FakeTensor.__torch_dispatch__:2281 | ProxyTorchDispatchMode.__torch_dispatch__:16285
Dynamo produced 1 graphs covering 436 ops with 4 graph breaks (3 unique)
cuda train hf_Bart                             1.095x p=0.00
TIMING: entire_frame_compile:19.44358 backend_compile:14.1414
STATS: call_* op count: 642 | FakeTensorMode.__torch_dispatch__:58035 | FakeTensor.__torch_dispatch__:11273 | ProxyTorchDispatchMode.__torch_dispatch__:22777
Dynamo produced 9 graphs covering 642 ops with 15 graph breaks (7 unique)
cuda train hf_Bert                             1.131x p=0.00
TIMING: entire_frame_compile:14.63842 backend_compile:11.96634
STATS: call_* op count: 367 | FakeTensorMode.__torch_dispatch__:38299 | FakeTensor.__torch_dispatch__:7267 | ProxyTorchDispatchMode.__torch_dispatch__:16812
Dynamo produced 1 graphs covering 367 ops with 4 graph breaks (3 unique)
cuda train hf_BigBird                          2.097x p=0.00
TIMING: entire_frame_compile:54.7419 backend_compile:45.64247
STATS: call_* op count: 2905 | FakeTensorMode.__torch_dispatch__:172782 | FakeTensor.__torch_dispatch__:9804 | ProxyTorchDispatchMode.__torch_dispatch__:81885
Dynamo produced 64 graphs covering 2905 ops with 60 graph breaks (8 unique)
cuda train hf_DistilBert                       1.113x p=0.00
TIMING: entire_frame_compile:8.97846 backend_compile:7.62566
STATS: call_* op count: 203 | FakeTensorMode.__torch_dispatch__:18952 | FakeTensor.__torch_dispatch__:3573 | ProxyTorchDispatchMode.__torch_dispatch__:8556
Dynamo produced 1 graphs covering 203 ops with 4 graph breaks (3 unique)
cuda train hf_GPT2                             1.352x p=0.00
TIMING: entire_frame_compile:14.67176 backend_compile:12.12394
STATS: call_* op count: 635 | FakeTensorMode.__torch_dispatch__:35211 | FakeTensor.__torch_dispatch__:4852 | ProxyTorchDispatchMode.__torch_dispatch__:15251
Dynamo produced 1 graphs covering 635 ops with 4 graph breaks (3 unique)
cuda train hf_Longformer                       Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 333, in call_function
    out = lowerings[target](*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/lowering.py", line 226, in wrapped
    validate_ir(out)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/ir.py", line 105, in validate_ir
    _check_tensorbox(node_or_nodes)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/ir.py", line 90, in _check_tensorbox
    assert isinstance(
AssertionError: Found <class 'torch._inductor.ir.DynamicScalar'>, which is not a supported top level IR node. See [Note: Inductor IR]
ERROR:common:Backend dynamo failed in warmup()
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 333, in call_function
    out = lowerings[target](*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/lowering.py", line 226, in wrapped
    validate_ir(out)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/ir.py", line 105, in validate_ir
    _check_tensorbox(node_or_nodes)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/ir.py", line 90, in _check_tensorbox
    assert isinstance(
AssertionError: Found <class 'torch._inductor.ir.DynamicScalar'>, which is not a supported top level IR node. See [Note: Inductor IR]

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 670, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.fake_example_inputs())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 1055, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/inductor.py", line 9, in inductor
    return compile_fx(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 455, in compile_fx
    return aot_autograd(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 48, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2805, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2498, in create_aot_dispatcher_function
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1713, in aot_wrapper_dedupe
    return compiler_fn(flat_fn, leaf_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1326, in aot_dispatch_base
    compiled_fw = aot_config.fw_compiler(fw_module, flat_args_with_views_handled)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 430, in fw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 176, in compile_fx_inner
    graph.run(*example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 194, in run
    return super().run(*args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/fx/interpreter.py", line 136, in run
    self.env[node] = self.run_node(node)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 407, in run_node
    result = super().run_node(n)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/fx/interpreter.py", line 177, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 337, in call_function
    raise LoweringException(e, target, args, kwargs) from e
torch._inductor.exc.LoweringException: AssertionError: Found <class 'torch._inductor.ir.DynamicScalar'>, which is not a supported top level IR node. See [Note: Inductor IR]
  target: aten._local_scalar_dense.default
  args[0]: TensorBox(StorageBox(
    Pointwise(
      'cpu',
      torch.int64,
      tmp0 = constant(1024, torch.int64)
      tmp1 = constant(512, torch.int64)
      tmp2 = truncdiv(tmp0, tmp1)
      return tmp2
      ,
      ranges=(),
      origins={div}
    )
  ))

While executing %_local_scalar_dense : [#users=0] = call_function[target=torch.ops.aten._local_scalar_dense.default](args = (%div,), kwargs = {})
Original traceback:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 769, in _chunk
    hidden_states = hidden_states.view(
 |   File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 839, in <graph break in _sliding_chunks_query_key_matmul>
    query = self._chunk(query, window_overlap, getattr(self.config, "onnx_export", False))


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in <graph break in forward_and_backward_pass>
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 1848, in forward
    outputs = self.longformer(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 1750, in forward
    encoder_outputs = self.encoder(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 1294, in forward
    is_global_attn = is_index_global_attn.flatten().any().item()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 1326, in <graph break in forward>
    layer_outputs = layer_module(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 1249, in forward
    self_attn_outputs = self.attention(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 1185, in forward
    self_outputs = self.self(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 574, in forward
    attn_scores = self._sliding_chunks_query_key_matmul(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 586, in <graph break in forward>
    diagonal_mask = self._sliding_chunks_query_key_matmul(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 839, in _sliding_chunks_query_key_matmul
    query = self._chunk(query, window_overlap, getattr(self.config, "onnx_export", False))
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 337, in catch_errors
    return callback(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 404, in _convert_frame
    result = inner_convert(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 104, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 262, in _convert_frame_assert
    return _compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 324, in _compile
    out_code = transform_code_object(code, transform)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 445, in transform_code_object
    transformations(instructions, code_options)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 311, in transform
    tracer.run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1726, in run
    super().run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 576, in run
    and self.step()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 540, in step
    getattr(self, inst.opname)(inst)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 372, in wrapper
    self.output.compile_subgraph(self, reason=reason)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 541, in compile_subgraph
    self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 588, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 675, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: inductor raised LoweringException: AssertionError: Found <class 'torch._inductor.ir.DynamicScalar'>, which is not a supported top level IR node. See [Note: Inductor IR]
  target: aten._local_scalar_dense.default
  args[0]: TensorBox(StorageBox(
    Pointwise(
      'cpu',
      torch.int64,
      tmp0 = constant(1024, torch.int64)
      tmp1 = constant(512, torch.int64)
      tmp2 = truncdiv(tmp0, tmp1)
      return tmp2
      ,
      ranges=(),
      origins={div}
    )
  ))

While executing %_local_scalar_dense : [#users=0] = call_function[target=torch.ops.aten._local_scalar_dense.default](args = (%div,), kwargs = {})
Original traceback:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 769, in _chunk
    hidden_states = hidden_states.view(
 |   File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/transformers/models/longformer/modeling_longformer.py", line 839, in <graph break in _sliding_chunks_query_key_matmul>
    query = self._chunk(query, window_overlap, getattr(self.config, "onnx_export", False))


Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True

ERROR
cuda train hf_Reformer                         ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 371, in <graph break in forward_and_backward_pass>
    self.grad_scaler.scale(loss).backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2348, in backward
    out = call_compiled_backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2319, in call_compiled_backward
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 38, in _wrapped_bw_compiler
    return eval_frame.disable(eval_frame.disable(bw_compiler)(*args, **kwargs))
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 441, in bw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/k6/ck6xws6rjquaby7xoxxu2frgojwcqqpalwc7tsfhksr74wjkh3st.py", line 200, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
ERROR
cuda train hf_T5                               ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 371, in <graph break in forward_and_backward_pass>
    self.grad_scaler.scale(loss).backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2348, in backward
    out = call_compiled_backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2319, in call_compiled_backward
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 38, in _wrapped_bw_compiler
    return eval_frame.disable(eval_frame.disable(bw_compiler)(*args, **kwargs))
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 441, in bw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/ox/cox2wd5tdbm2qiexplpplhtfdcoc4uw6ysi7fqsgkuhv4zi44m47.py", line 4532, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
ERROR
cuda train maml_omniglot                       1.436x p=0.00
TIMING: entire_frame_compile:4.27212 backend_compile:3.90682
STATS: call_* op count: 14 | FakeTensor.__torch_dispatch__:473 | FakeTensorMode.__torch_dispatch__:1913 | ProxyTorchDispatchMode.__torch_dispatch__:720
Dynamo produced 1 graphs covering 14 ops with 5 graph breaks (4 unique)
cuda train mnasnet1_0                          1.186x p=0.00
TIMING: entire_frame_compile:17.37429 backend_compile:13.52094
STATS: call_* op count: 152 | FakeTensor.__torch_dispatch__:5378 | FakeTensorMode.__torch_dispatch__:25651 | ProxyTorchDispatchMode.__torch_dispatch__:9498
Dynamo produced 1 graphs covering 152 ops with 5 graph breaks (4 unique)
cuda train mobilenet_v2                        1.354x p=0.00
TIMING: entire_frame_compile:16.8437 backend_compile:15.007
STATS: call_* op count: 153 | FakeTensor.__torch_dispatch__:5413 | FakeTensorMode.__torch_dispatch__:26205 | ProxyTorchDispatchMode.__torch_dispatch__:9892
Dynamo produced 1 graphs covering 153 ops with 5 graph breaks (4 unique)
cuda train mobilenet_v2_quantized_qat          ERROR:common:Backend dynamo failed in warmup()
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 371, in <graph break in forward_and_backward_pass>
    self.grad_scaler.scale(loss).backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2310, in backward
    list(ctx.symints) + list(ctx.saved_tensors) + list(contiguous_args)
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
ERROR
cuda train mobilenet_v3_large                  1.376x p=0.00
TIMING: entire_frame_compile:16.60157 backend_compile:14.69578
STATS: call_* op count: 187 | FakeTensor.__torch_dispatch__:6012 | FakeTensorMode.__torch_dispatch__:27516 | ProxyTorchDispatchMode.__torch_dispatch__:10662
Dynamo produced 1 graphs covering 187 ops with 5 graph breaks (4 unique)
cuda train moco                                   function: '<graph break in _momentum_update_key_encoder>' (/scratch/voz/work/torchbenchmark/torchbenchmark/models/moco/moco/builder.py:50)
   reasons:  ___tuple_iterator_len(___stack0) == 160
to diagnose recompilation issues, see https://pytorch.org/docs/master/dynamo/troubleshooting.html.
ERROR:common:Backend dynamo failed in warmup()
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 670, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.fake_example_inputs())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/distributed.py", line 203, in compile_fn
    return self.backend_compile_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 1055, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/inductor.py", line 9, in inductor
    return compile_fx(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 455, in compile_fx
    return aot_autograd(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 48, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2805, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2498, in create_aot_dispatcher_function
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1674, in aot_wrapper_dedupe
    fw_metadata, _out = run_functionalized_fw_and_collect_metadata(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 606, in inner
    flat_f_outs = f(*flat_f_args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2776, in functional_call
    out = Interpreter(mod).run(*args[params_len:], **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/fx/interpreter.py", line 136, in run
    self.env[node] = self.run_node(node)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/fx/interpreter.py", line 177, in run_node
    return getattr(self, n.op)(n.target, args, kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/fx/interpreter.py", line 249, in call_function
    return target(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1436, in wrapper
    return func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 2433, in all_gather
    work = default_pg.allgather([tensor_list], [tensor])
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/utils/_stats.py", line 20, in wrapper
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 987, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1066, in dispatch
    args, kwargs = self.validate_and_convert_non_fake_tensors(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1220, in validate_and_convert_non_fake_tensors
    return tree_map_only(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/utils/_pytree.py", line 266, in tree_map_only
    return tree_map(map_only(ty)(fn), pytree)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/utils/_pytree.py", line 196, in tree_map
    return tree_unflatten([fn(i) for i in flat_args], spec)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/utils/_pytree.py", line 196, in <listcomp>
    return tree_unflatten([fn(i) for i in flat_args], spec)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/utils/_pytree.py", line 247, in inner
    return f(x)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_subclasses/fake_tensor.py", line 1212, in validate
    raise Exception(
Exception: Please convert all Tensors to FakeTensors first or instantiate FakeTensorMode with 'allow_non_fake_inputs'. Found in c10d.allgather_.default(*([[_to_functional_tensor(FakeTensor(FakeTensor(..., device='meta', size=(32, 3, 224, 224)), cuda:0),
       device='cuda:0')]], [FakeTensor(FakeTensor(..., device='meta', size=(32, 3, 224, 224)), cuda:0)], <torch.ScriptObject object at 0x7fb00152e1f0>, -1), **{}) 

While executing %all_gather : [#users=0] = call_function[target=torch.distributed.distributed_c10d.all_gather](args = ([%ones_like], %tensor), kwargs = {async_op: False})
Original traceback:
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/moco/moco/builder.py", line 172, in concat_all_gather
    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in <graph break in forward_and_backward_pass>
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/moco/moco/builder.py", line 130, in forward
    self._momentum_update_key_encoder()  # update the key encoder
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/moco/moco/builder.py", line 133, in <graph break in forward>
    im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/moco/moco/builder.py", line 76, in _batch_shuffle_ddp
    x_gather = concat_all_gather(x)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 334, in catch_errors
    return hijacked_callback(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 404, in _convert_frame
    result = inner_convert(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 104, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 262, in _convert_frame_assert
    return _compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 324, in _compile
    out_code = transform_code_object(code, transform)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 445, in transform_code_object
    transformations(instructions, code_options)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 311, in transform
    tracer.run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1726, in run
    super().run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 576, in run
    and self.step()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 540, in step
    getattr(self, inst.opname)(inst)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1792, in RETURN_VALUE
    self.output.compile_subgraph(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 517, in compile_subgraph
    self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 588, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 675, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: compile_fn raised Exception: Please convert all Tensors to FakeTensors first or instantiate FakeTensorMode with 'allow_non_fake_inputs'. Found in c10d.allgather_.default(*([[_to_functional_tensor(FakeTensor(FakeTensor(..., device='meta', size=(32, 3, 224, 224)), cuda:0),
       device='cuda:0')]], [FakeTensor(FakeTensor(..., device='meta', size=(32, 3, 224, 224)), cuda:0)], <torch.ScriptObject object at 0x7fb00152e1f0>, -1), **{}) 

While executing %all_gather : [#users=0] = call_function[target=torch.distributed.distributed_c10d.all_gather](args = ([%ones_like], %tensor), kwargs = {async_op: False})
Original traceback:
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/moco/moco/builder.py", line 172, in concat_all_gather
    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)


Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True

ERROR
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 386, in <module>
    torchbench_main()
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 382, in torchbench_main
    main(TorchBenchmarkRunner(), original_dir)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1919, in main
    return maybe_fresh_cache(
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 988, in inner
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 2269, in run
    ) = runner.load_model(device, model_name, batch_size=batch_size)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 249, in load_model
    module = importlib.import_module(f"torchbenchmark.models.{model_name}")
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/nvidia_deeprecommender/__init__.py", line 12, in <module>
    from torchbenchmark.models.attention_is_all_you_need_pytorch.train import train
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/attention_is_all_you_need_pytorch/__init__.py", line 12, in <module>
    from torchbenchmark.util.torchtext_legacy.field import Field
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/util/torchtext_legacy/field.py", line 6, in <module>
    from .data import Dataset
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/util/torchtext_legacy/data.py", line 13, in <module>
    from torchtext.data.utils import RandomShuffler
  File "/scratch/voz/work/torchtext/torchtext/__init__.py", line 6, in <module>
    from torchtext import _extension  # noqa: F401
  File "/scratch/voz/work/torchtext/torchtext/_extension.py", line 64, in <module>
    _init_extension()
  File "/scratch/voz/work/torchtext/torchtext/_extension.py", line 58, in _init_extension
    _load_lib("libtorchtext")
  File "/scratch/voz/work/torchtext/torchtext/_extension.py", line 50, in _load_lib
    torch.ops.load_library(path)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_ops.py", line 643, in load_library
    ctypes.CDLL(path)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/ctypes/__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: /scratch/voz/work/torchtext/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
ERROR
cuda train pytorch_CycleGAN_and_pix2pix        ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 670, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.fake_example_inputs())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 1055, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/inductor.py", line 9, in inductor
    return compile_fx(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 455, in compile_fx
    return aot_autograd(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 48, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2805, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2498, in create_aot_dispatcher_function
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1713, in aot_wrapper_dedupe
    return compiler_fn(flat_fn, leaf_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2133, in aot_dispatch_autograd
    compiled_fw_func = aot_config.fw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 430, in fw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/ac/cacjsqagqostcrrkj6k6z6p7zw5oqhslov7gjxs27pcx6fpjjbzc.py", line 692, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in <graph break in forward_and_backward_pass>
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 337, in catch_errors
    return callback(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 404, in _convert_frame
    result = inner_convert(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 104, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 262, in _convert_frame_assert
    return _compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 324, in _compile
    out_code = transform_code_object(code, transform)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 445, in transform_code_object
    transformations(instructions, code_options)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 311, in transform
    tracer.run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1726, in run
    super().run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 576, in run
    and self.step()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 540, in step
    getattr(self, inst.opname)(inst)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1792, in RETURN_VALUE
    self.output.compile_subgraph(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 517, in compile_subgraph
    self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 588, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 675, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: inductor raised FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True

ERROR
cuda train pytorch_stargan                     1.191x p=0.00
TIMING: entire_frame_compile:8.11937 backend_compile:7.30677
STATS: call_* op count: 56 | FakeTensorMode.__torch_dispatch__:12560 | FakeTensor.__torch_dispatch__:2056 | ProxyTorchDispatchMode.__torch_dispatch__:5015
Dynamo produced 1 graphs covering 56 ops with 5 graph breaks (4 unique)
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 249, in load_model
    module = importlib.import_module(f"torchbenchmark.models.{model_name}")
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/pytorch_struct/__init__.py", line 6, in <module>
    import pytest
ModuleNotFoundError: No module named 'pytest'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 386, in <module>
    torchbench_main()
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 382, in torchbench_main
    main(TorchBenchmarkRunner(), original_dir)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1919, in main
    return maybe_fresh_cache(
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 988, in inner
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 2269, in run
    ) = runner.load_model(device, model_name, batch_size=batch_size)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 251, in load_model
    module = importlib.import_module(f"torchbenchmark.models.fb.{model_name}")
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 992, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1004, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'torchbenchmark.models.fb'
ERROR
cuda train pytorch_unet                        1.209x p=0.00
TIMING: entire_frame_compile:9.25961 backend_compile:8.27097
STATS: call_* op count: 71 | FakeTensor.__torch_dispatch__:2551 | FakeTensorMode.__torch_dispatch__:13881 | ProxyTorchDispatchMode.__torch_dispatch__:5501
Dynamo produced 1 graphs covering 71 ops with 5 graph breaks (4 unique)
cuda train resnet18                            1.156x p=0.00
TIMING: entire_frame_compile:8.89318 backend_compile:8.00909
STATS: call_* op count: 69 | FakeTensor.__torch_dispatch__:2114 | FakeTensorMode.__torch_dispatch__:10163 | ProxyTorchDispatchMode.__torch_dispatch__:3848
Dynamo produced 1 graphs covering 69 ops with 5 graph breaks (4 unique)
cuda train resnet50                            1.114x p=0.00
TIMING: entire_frame_compile:17.37649 backend_compile:13.57281
STATS: call_* op count: 175 | FakeTensor.__torch_dispatch__:5480 | FakeTensorMode.__torch_dispatch__:26429 | ProxyTorchDispatchMode.__torch_dispatch__:9995
Dynamo produced 1 graphs covering 175 ops with 5 graph breaks (4 unique)
cuda train resnet50_quantized_qat              ERROR:common:Backend dynamo failed in warmup()
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 371, in <graph break in forward_and_backward_pass>
    self.grad_scaler.scale(loss).backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2310, in backward
    list(ctx.symints) + list(ctx.saved_tensors) + list(contiguous_args)
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [64]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
ERROR
cuda train resnext50_32x4d                     ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 371, in <graph break in forward_and_backward_pass>
    self.grad_scaler.scale(loss).backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2348, in backward
    out = call_compiled_backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2319, in call_compiled_backward
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 38, in _wrapped_bw_compiler
    return eval_frame.disable(eval_frame.disable(bw_compiler)(*args, **kwargs))
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 441, in bw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/l3/cl3qipxfxj6lotrzxg3ql5ms64rnsjat6mm2av5jt6ctzvdptxvk.py", line 2439, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
ERROR
cuda train shufflenet_v2_x1_0                  1.335x p=0.00
TIMING: entire_frame_compile:17.39095 backend_compile:15.34997
STATS: call_* op count: 271 | FakeTensor.__torch_dispatch__:5786 | FakeTensorMode.__torch_dispatch__:30411 | ProxyTorchDispatchMode.__torch_dispatch__:11450
Dynamo produced 1 graphs covering 271 ops with 5 graph breaks (4 unique)
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 386, in <module>
    torchbench_main()
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 382, in torchbench_main
    main(TorchBenchmarkRunner(), original_dir)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1919, in main
    return maybe_fresh_cache(
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 988, in inner
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 2269, in run
    ) = runner.load_model(device, model_name, batch_size=batch_size)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 275, in load_model
    benchmark = benchmark_cls(
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/util/model.py", line 13, in __call__
    obj = type.__call__(cls, *args, **kwargs)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/soft_actor_critic/__init__.py", line 131, in __init__
    self.train_env = load_gym(self.args.env_id, self.args.seed)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/soft_actor_critic/envs.py", line 237, in load_gym
    env.seed(seed)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/gym/core.py", line 241, in __getattr__
    return getattr(self.env, name)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/gym/core.py", line 241, in __getattr__
    return getattr(self.env, name)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/gym/core.py", line 241, in __getattr__
    return getattr(self.env, name)
  [Previous line repeated 1 more time]
AttributeError: 'PendulumEnv' object has no attribute 'seed'
ERROR
cuda train speech_transformer                  ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 670, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.fake_example_inputs())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 1055, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/inductor.py", line 9, in inductor
    return compile_fx(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 455, in compile_fx
    return aot_autograd(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 48, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2805, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2498, in create_aot_dispatcher_function
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1713, in aot_wrapper_dedupe
    return compiler_fn(flat_fn, leaf_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2133, in aot_dispatch_autograd
    compiled_fw_func = aot_config.fw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 430, in fw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/dp/cdpsuv5h25kkhof4opulbccjnvbssmqatpaeucwzhwc4rnou3rka.py", line 1779, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in <graph break in forward_and_backward_pass>
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/speech_transformer/speech_transformer/transformer/transformer.py", line 28, in forward
    encoder_padded_outputs, *_ = self.encoder(padded_input, input_lengths)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/speech_transformer/speech_transformer/transformer/encoder.py", line 48, in forward
    non_pad_mask = get_non_pad_mask(padded_input, input_lengths=input_lengths)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/speech_transformer/speech_transformer/transformer/encoder.py", line 50, in <graph break in forward>
    slf_attn_mask = get_attn_pad_mask(padded_input, input_lengths, length)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 337, in catch_errors
    return callback(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 404, in _convert_frame
    result = inner_convert(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 104, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 262, in _convert_frame_assert
    return _compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 324, in _compile
    out_code = transform_code_object(code, transform)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 445, in transform_code_object
    transformations(instructions, code_options)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 311, in transform
    tracer.run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1726, in run
    super().run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 576, in run
    and self.step()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 540, in step
    getattr(self, inst.opname)(inst)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1792, in RETURN_VALUE
    self.output.compile_subgraph(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 541, in compile_subgraph
    self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 588, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 675, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: inductor raised FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True

ERROR
cuda train squeezenet1_1                       1.273x p=0.00
TIMING: entire_frame_compile:5.51961 backend_compile:4.88579
STATS: call_* op count: 66 | FakeTensor.__torch_dispatch__:1854 | FakeTensorMode.__torch_dispatch__:4618 | ProxyTorchDispatchMode.__torch_dispatch__:1788
Dynamo produced 1 graphs covering 66 ops with 5 graph breaks (4 unique)
ERROR
cuda train timm_efficientnet                   ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 371, in <graph break in forward_and_backward_pass>
    self.grad_scaler.scale(loss).backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2348, in backward
    out = call_compiled_backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2319, in call_compiled_backward
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 38, in _wrapped_bw_compiler
    return eval_frame.disable(eval_frame.disable(bw_compiler)(*args, **kwargs))
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 441, in bw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/l7/cl72fgigdsrvtrl3n54numz2l4cjiljvt5eky2nxqauecaajkb7h.py", line 5034, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
ERROR
cuda train timm_nfnet                          1.405x p=0.00
TIMING: entire_frame_compile:19.00218 backend_compile:15.59598
STATS: call_* op count: 615 | FakeTensorMode.__torch_dispatch__:38859 | FakeTensor.__torch_dispatch__:7736 | ProxyTorchDispatchMode.__torch_dispatch__:16545
Dynamo produced 1 graphs covering 615 ops with 5 graph breaks (4 unique)
cuda train timm_regnet                         ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 371, in <graph break in forward_and_backward_pass>
    self.grad_scaler.scale(loss).backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2348, in backward
    out = call_compiled_backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2319, in call_compiled_backward
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 38, in _wrapped_bw_compiler
    return eval_frame.disable(eval_frame.disable(bw_compiler)(*args, **kwargs))
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 441, in bw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/nc/cnczxe35ikavpzyckchbsd52plknjvzh2iwtrcpou7glvdzb33sx.py", line 3434, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
ERROR
cuda train timm_resnest                        ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 670, in call_user_compiler
    compiled_fn = compiler_fn(gm, self.fake_example_inputs())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 1055, in debug_wrapper
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/inductor.py", line 9, in inductor
    return compile_fx(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 455, in compile_fx
    return aot_autograd(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 48, in compiler_fn
    cg = aot_module_simplified(gm, example_inputs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2805, in aot_module_simplified
    compiled_fn = create_aot_dispatcher_function(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2498, in create_aot_dispatcher_function
    compiled_fn = compiler_fn(flat_fn, fake_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1713, in aot_wrapper_dedupe
    return compiler_fn(flat_fn, leaf_flat_args, aot_config)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2133, in aot_dispatch_autograd
    compiled_fw_func = aot_config.fw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 430, in fw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/3h/c3hdn4zmvwoj5tyifzgeqtqgxa3eusxt4jq6v3xvrxc7h5ifr4y4.py", line 3245, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 369, in <graph break in forward_and_backward_pass>
    pred = mod(*cloned_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 337, in catch_errors
    return callback(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 404, in _convert_frame
    result = inner_convert(frame, cache_size, hooks)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 104, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 262, in _convert_frame_assert
    return _compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 324, in _compile
    out_code = transform_code_object(code, transform)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py", line 445, in transform_code_object
    transformations(instructions, code_options)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py", line 311, in transform
    tracer.run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1726, in run
    super().run()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 576, in run
    and self.step()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 540, in step
    getattr(self, inst.opname)(inst)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py", line 1792, in RETURN_VALUE
    self.output.compile_subgraph(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 517, in compile_subgraph
    self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 588, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/output_graph.py", line 675, in call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: inductor raised FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'

Set torch._dynamo.config.verbose=True for more information


You can suppress this exception and fall back to eager by setting:
    torch._dynamo.config.suppress_errors = True

ERROR
cuda train timm_vision_transformer             ERROR:common:Backend dynamo failed in warmup()
concurrent.futures.process._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/process.py", line 246, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 549, in _worker_compile
    kernel.precompile(warm_cache_only_with_cc=cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 69, in precompile
    self.launchers = [
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 70, in <listcomp>
    self._precompile_config(c, warm_cache_only_with_cc)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/triton_ops/autotune.py", line 83, in _precompile_config
    triton.compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1588, in compile
    so_path = make_stub(name, signature, constants)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1477, in make_stub
    so = _build(name, src_path, tmpdir)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/triton/compiler.py", line 1392, in _build
    ret = subprocess.check_call(cc_cmd)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 364, in check_call
    retcode = call(*popenargs, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 345, in call
    with Popen(*popenargs, **kwargs) as p:
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 971, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/subprocess.py", line 1847, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1376, in warmup
    fn(model, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 366, in forward_and_backward_pass
    cloned_inputs = clone_inputs(inputs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 367, in <graph break in forward_and_backward_pass>
    self.optimizer_zero_grad(mod)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 371, in <graph break in forward_and_backward_pass>
    self.grad_scaler.scale(loss).backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2348, in backward
    out = call_compiled_backward()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2319, in call_compiled_backward
    CompiledFunction.compiled_bw = aot_config.bw_compiler(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/backends/common.py", line 38, in _wrapped_bw_compiler
    return eval_frame.disable(eval_frame.disable(bw_compiler)(*args, **kwargs))
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 441, in bw_compiler
    return inner_compile(
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py", line 595, in debug_wrapper
    compiled_fn = compiler_fn(gm, example_inputs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/debug.py", line 239, in inner
    return fn(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 177, in compile_fx_inner
    compiled_fn = graph.compile_to_fn()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 586, in compile_to_fn
    return self.compile_to_module().call
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_dynamo/utils.py", line 163, in time_wrapper
    r = func(*args, **kwargs)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/graph.py", line 575, in compile_to_module
    mod = PyCodeCache.load(code)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 528, in load
    exec(code, mod.__dict__, mod.__dict__)
  File "/tmp/torchinductor_voz/uy/cuy5ar7r42xf3gbwid5rloifw5k7v4fmqxoksc7vtwf62r7k4wac.py", line 894, in <module>
    async_compile.wait(globals())
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 715, in wait
    scope[key] = result.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 573, in result
    self.future.result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
FileNotFoundError: [Errno 2] No such file or directory: 'clang-8'
ERROR
cuda train timm_vovnet                         1.098x p=0.00
TIMING: entire_frame_compile:13.6703 backend_compile:11.68187
STATS: call_* op count: 208 | FakeTensor.__torch_dispatch__:3896 | FakeTensorMode.__torch_dispatch__:19893 | ProxyTorchDispatchMode.__torch_dispatch__:7693
Dynamo produced 1 graphs covering 208 ops with 5 graph breaks (4 unique)
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 386, in <module>
    torchbench_main()
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 382, in torchbench_main
    main(TorchBenchmarkRunner(), original_dir)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1919, in main
    return maybe_fresh_cache(
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 988, in inner
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 2269, in run
    ) = runner.load_model(device, model_name, batch_size=batch_size)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 275, in load_model
    benchmark = benchmark_cls(
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/util/model.py", line 13, in __call__
    obj = type.__call__(cls, *args, **kwargs)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/tts_angular/__init__.py", line 20, in __init__
    self.model = TTSModel(device=self.device, batch_size=self.batch_size)
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/tts_angular/angular_tts_main.py", line 244, in __init__
    self.model = self.model.cuda()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 905, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 202, in _apply
    self._init_flat_weights()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 139, in _init_flat_weights
    self.flatten_parameters()
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 169, in flatten_parameters
    not torch.backends.cudnn.is_acceptable(fw.data)):
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/backends/cudnn/__init__.py", line 97, in is_acceptable
    if not _init():
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/torch/backends/cudnn/__init__.py", line 52, in _init
    raise RuntimeError(f'{base_error_msg}'
RuntimeError: cuDNN version incompatibility: PyTorch was compiled  against (8, 5, 0) but found runtime version (8, 4, 1). PyTorch already comes bundled with cuDNN. One option to resolving this error is to ensure PyTorch can find the bundled cuDNN.Looks like your LD_LIBRARY_PATH contains incompatible version of cudnnPlease either remove it from the path or install cudnn (8, 5, 0)
ERROR
cuda train vgg16                               1.154x p=0.00
TIMING: entire_frame_compile:4.92063 backend_compile:4.43281
STATS: call_* op count: 40 | FakeTensor.__torch_dispatch__:1135 | FakeTensorMode.__torch_dispatch__:3092 | ProxyTorchDispatchMode.__torch_dispatch__:1175
Dynamo produced 1 graphs covering 40 ops with 5 graph breaks (4 unique)
Traceback (most recent call last):
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 386, in <module>
    torchbench_main()
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 382, in torchbench_main
    main(TorchBenchmarkRunner(), original_dir)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 1919, in main
    return maybe_fresh_cache(
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 988, in inner
    return fn(*args, **kwargs)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/common.py", line 2269, in run
    ) = runner.load_model(device, model_name, batch_size=batch_size)
  File "/scratch/voz/work/pytorch/benchmarks/dynamo/torchbench.py", line 249, in load_model
    module = importlib.import_module(f"torchbenchmark.models.{model_name}")
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/vision_maskrcnn/__init__.py", line 17, in <module>
    from .coco_utils import ConvertCocoPolysToMask
  File "/scratch/voz/work/torchbenchmark/torchbenchmark/models/vision_maskrcnn/coco_utils.py", line 2, in <module>
    from pycocotools import mask as coco_mask
  File "/data/home/voz/miniconda3/envs/benchmarks/lib/python3.10/site-packages/pycocotools-2.0.6-py3.10-linux-x86_64.egg/pycocotools/mask.py", line 3, in <module>
    import pycocotools._mask as _mask
  File "pycocotools/_mask.pyx", line 1, in init pycocotools._mask
ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject
ERROR
cuda train yolov3                              1.124x p=0.00
TIMING: entire_frame_compile:24.50818 backend_compile:19.64297
STATS: call_* op count: 262 | FakeTensor.__torch_dispatch__:7756 | FakeTensorMode.__torch_dispatch__:38085 | ProxyTorchDispatchMode.__torch_dispatch__:14717
Dynamo produced 1 graphs covering 262 ops with 5 graph breaks (4 unique)
speedup             gmean=1.12x mean=1.134x
abs_latency         gmean=nanx mean=42.552x
compilation_latency mean=19.055 seconds
compression_ratio   mean=0.876x
eager_peak_mem      gmean=nanx mean=4.244x
dynamo_peak_mem     gmean=nanx mean=4.827x
calls_captured      gmean=nanx mean=322.692x
unique_graphs       gmean=nanx mean=3.731x
graph_breaks        gmean=nanx mean=7.308x
unique_graph_breaks gmean=nanx mean=4.077x
